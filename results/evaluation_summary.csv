model,QA_score,reasoning_score,chat_score,code_score,overall_score,total_prompts
vllm,0.0489766191811984,0.875,0.1649614115090419,0.0507927000556858,0.2849326826864815,520
vllm_fp8_quantization,0.0492145113996344,0.8666666666666667,0.2126636673230678,0.0505044452190106,0.2947623226520949,520
baseline_llama_cpp,0.0136016573610596,0.8833333333333333,0.2194899274346729,0.0601913385367631,0.2941540641664573,520
sglang-torch-compile,0.0492781030411824,0.9,0.1846236157541473,0.0505346304706419,0.296109087316493,520
sglang,0.0496638065094178,0.8666666666666667,0.18084658862013991,0.05136078497160803,0.2871344616919581,520
